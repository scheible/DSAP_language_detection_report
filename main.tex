% Template for ICASSP-2016 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Speech Language Recognition Combining Phoneme Detection Statistical Analysis and Neural Networks}
%
% Single address.
% ---------------
\name{Quentin Deleuil, Gianmarco Garrisi, Qianyun Hu, Patrik Scheible \thanks{Thanks to XYZ agency for funding.}}
\address{s212260@studenti.polito.it, patrikscheible@posteo.net, }
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
The abstract should appear at the top of the left-hand column of text, about
0.5 inch (12 mm) below the title area and no more than 3.125 inches (80 mm) in
length.  Leave a 0.5 inch (12 mm) space between the end of the abstract and the
beginning of the main text.  The abstract should contain about 100 to 150
words, and should be identical to the abstract text submitted electronically
along with the paper cover sheet.  All manuscripts must be in English, printed
in black ink.
\end{abstract}
%
\begin{keywords}
One, two, three, four, five
\end{keywords}
%
\section{Introduction}
\label{sec:intro}
Spoken language identification is to classify the spoken language from a given audio sample, which is typically the first step for language processing tasks. Without spoken language detection, speech utterances cannot be analyzed correctly and the grammar rules cannot be applied. As with speech recognition, humans can perform the most accurate language identification. Within a few seconds of hearing, people are able to identify if they have prior knowledge of this language. In the other case, people can just make subjective judgements to the similarity of the language they know.

There are several critical applications for spoken language identification, such as international emergency call for urgent occasions and language predefined for intelligent assistants like Siri. 
Thus, a spoken language identification system should be developed for such cases.

In our project, we explore two different approaches, Phoneme Statistical Analysis (PSA) and Deep Neural Network (DNN), to identifying the language of speech. Five languages, Arabic, Dutch, Korean, Polish and Romanian from Topcoder are used as database. The inputs are 10  seconds audio segment files in type of “wav.” and outputs are the label of the language. In the PSA approach, we extract the phonemes and build a statistical analysis model for each language. While in DNN approach, we transform information from the audio signal to Mel-frequency Cepstral Coefficients (MFCC) and use Convolutional Neural Network (CNN) combined with Recurrent Neural Network (RNN) to train the system.

The report is structured in the following way: In Sect 2 we introduce the system of PSA. The approach with DNN will be shown in Sect.3. Finally, in Sect. 4 we conclude our work with comparison of both systems. 

\section{Phoneme Statistical Analysis}
\subsection{Technique}
The first step in this approach is to convert all audio files in the training set into their corresponding phonemes using the framework CMU Sphinx \cite{lamere2003cmu}. Since the project scope does not allow to create a neutral language model for CMU Sphinx the standard American English model is used. Thus rather low performance of the actual phoneme recognition can be assumed \cite{kepuska2017comparing}. However the goal is to identify a language even with a bad phoneme recogniser.

In the second step, n-grams of the phonemes of each language are computed. \cite{matejka2005phonotactic} used 3-grams to model a language however this requires more training data than for this project is available. Therefore histograms (1-grams) and 2-grams are considered.

\subsection{Experiments}




\vfill\pagebreak

\section{REFERENCES}
\label{sec:refs}


% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
